\documentclass[12pt, letterpaper]{article}
%\usepackage[top=2cm,bottom=4cm,left=1.5cm,right=3cm,asymmetric]{geometry} aggiungere ^twoside^
\usepackage{fancyhdr}
\pagestyle{fancy}

 \fancyfoot[C]{}    
 \fancyfoot[LE,RO]{\thepage}        
 \fancyhead[RO]{\slshape \rightmark}        
 \fancyhead[LE]{\slshape\leftmark}      
  \fancyhead[RE,LO]{}  

%%%%%
\usepackage{xcolor}
\usepackage{listings}

\definecolor{mGreen}{rgb}{0,0.6,0}
\definecolor{mGray}{rgb}{0.5,0.5,0.5}
\definecolor{mPurple}{rgb}{0.58,0,0.82}
\definecolor{backgroundColour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{CStyle}{
    backgroundcolor=\color{backgroundColour},   
    commentstyle=\color{mGreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{mGray},
    stringstyle=\color{mPurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=C
}
%%%%%
\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\newcommand{\img}[3] {
	\begin{figure}[h]
		\caption{#1}
		\centering
		\includegraphics[scale=#2]{#3}\\
	\end{figure}
}

\title{La Bibbia di Sistemi operativi}
\author{Mario Petruccelli \cr Università degli studi di Milano}
\date{A.A. 2018/2019}

\addto\captionsenglish{% Replace "english" with the language you use
  \renewcommand{\contentsname}
    {Sommario}
}

\begin{document}

	\begin{titlepage} \maketitle \newpage \tableofcontents \end{titlepage}
	
	\section{Virtualization}
		
		\subsection{Introduzione}
		
			\paragraph{Processi} Un processo, informalmente, è un programma in esecuzione. Un programma a sua volta, è una sequenza finita di istruzioni scritte in un linguaggio comprensibile all'esecutore (CPU).
				L'esecuzione di un programma da parte del processore è:
				\begin{itemize}
					\item \textbf{Fetch} Prelievo istruzione dalla memoria.
					\item \textbf{Decode} Decodifica dell'istruzione.
					\item \textbf{Execute} Esecuzione dell'istruzione.
				\end{itemize}
			
			\subsubsection{Virtualizzazione} La virtualizzazione consiste nel prendere una risorsa fisica e trasformarla in una più generale, potente e facile da adoperare forma virtuale di se stessa. 
			
				\paragraph{Virtualizzazione della CPU} L'illusione consiste nel far credere che il sistema abbia un elevato numero di cpu virtuali. Avere più CPU permeterrebbe a più programmi di essere eseguiti in \textbf{parallelo} nonostante il processore fisico effettivo sia uno solo. Se due processi vogliono essere eseguiti entrambi ad un certo tempo, oppure vogliono accedere alla stessa periferica, quale dei due ha la priorità? La risposta viene data con l'introduzione delle politiche di priorità (\textbf{politiche di scheduling}).
			
				\paragraph{Virtualizzazione della memoria} Consiste nel fabbricare l'illusione che ogni processo abbia il proprio spazio di indirizzi virtuali privato (\textbf{address space}) al quale accede e sarà il sistema operativo ad occuparsi di mappare nella memoria fisica.\\
						
				Con la virtualizzazione è fondamentale riuscire a distinguere i processi in esecuzione. Per fare ciò viene associato un \textbf{PID} (process id) ad ogni job. il PID è un numero univoco.
		
			\subsubsection{Concorrenza} Si riferisce a tutta quelle serie di problemi che sorgono, e che vanno risolti, quando all'interno dello stesso programma più entità lavorano in parallelo. Le entità in questione si chiamano \textbf{threads}.
			
			\subsubsection{Persistenza} La persistenza è legata alla memorizzazione dei dati all'interno della memoria. La non volatilità delle memorie ha introdotto la possibilità di memorizzare dati in modo persistente. Il software nel sistema operativo che generalmente gestisce i dischi è chiamato \textbf{file system}.
			
			\subsubsection{Protezione ad anelli}
				Un modello di potezione implementato dal sistema operativo è quello ad anelli. Ci sono 5 livelli e 3 anelli differenti. A ciascun anello corrisponde un relativo livello di sicurezza. 
				\begin{itemize}
					\item \textbf{Level 1}\textit{ Hardware level} qui vengono eseguiti, ad esempio, i device drivers visto che essi richiedono accesso diretto all'hardware dei dispositivi (microcontroller).
					\item \textbf{Level 2}\textit{ Firmware level} Il  firmware sta in cima al livello elettronico. Contiene in software necessario dal dispositivo hardware e dal microcontroller. 
					\item \textbf{Level 3: ring 0}\textit{ Kernel level} Questo è il livello dove opera il kernel, dopo la fase di bootload siamo qui.
					\item \textbf{Level 4: ring 1 e 2}\textit{ Device drivers} I device drivers passano atraverso il kernel per accedere all'hardware.
					\item \textbf{Level 5: ring 3}\textit{ Application level} Qui è dove viene eseguito normalemente il codice utente.
				\end{itemize}
						
		\subsection{Processi}
			
			\paragraph{Sistema multiprogrammato} Sistema nel quale è possibile eseguire più programmi contemporaneamente, idea alla base della virtualizzazione.
			
			\subsubsection{Multiprogrammazione}
				
				\paragraph{Time sharing} prevede che il tempo di CPU sia equamente diviso fra i programmi in memoria. 
				\paragraph{Real time sharing} La politica di scheduling è differente. Alcuni processi vanno serviti prima di altri.
				
			\subsubsection{Virtualizzazione della CPU}
				L'illusione consiste nel rendere indipendenti il numero di processi dal numero di processori. Si vuole disaccoppiare le entità logiche (\textit{processi}), dalle entità fisiche (\textit{processori}), in modo tale che ad ogni processo venga assegnato un processore logico mappato su processore fisico.
				
				I concetti fondamentali alla base della virtualizzazione sono: 
				\begin{itemize}
					\item \textbf{Time sharing} Meccanismo mediante il quale il tempo di CPU viene diviso equamente fra i processi.
					\item \textbf{Context switch} Meccanismo che consente di interrompere l'esecuzione di un processo in corso sulla CPU fisica e assegnare quest'ultima ad un nuovo processo.
				\end{itemize}				 
				
			\subsubsection{Processi} Un processo è un programma in esecuzione, il sistema operativo deve fornire alcune interfacce (\textbf{APIs}) per la gestione dei processi che permettano di fare:
			
				\begin{itemize}
					\item \textbf{Create} Creazione di un nuovo processo.
					\item \textbf{Destroy} Eliminazione forzata di un processo. Molti processi termineranno per conto loro, ma l'utente potrebbe voler eliminare processi non ancora terminati.
					\item \textbf{Wait} Mette in attesa un processo. 
					\item \textbf{Miscellaneous control} Sospensione di un processo per farlo ripartire dopo un certo tempo.
					\item \textbf{Status} Interfacce che restituiscono lo stato e altre informazioni di un processo.
				\end{itemize}
				
				\paragraph{Creazione di un processo} La prima cosa che deve fare il sistema operativo per eseguire un programma è caricare il suo codice ed eventuali dati statici da disco a memoria, nell'address space del processo.
					\begin{itemize}
						\item \textbf{Allocazione dello stack} Un po' di memoria deve essere creata per lo stack del programma 	(\textit{variabili locali, parametri delle funzioni e indirizzi di ritorno}).	
						\item \textbf{Allocazione dello heap}  Un po' di memoria deve essere creata per lo heap del programma (\textit{dati allocati dinamicamente}).
						\item \textbf{Inizializzazione I/O} Standard input, output ed error.
						\item \textbf{Salto ed esecuzione} Salto all'entry point ed esecuzione. (\textit{main}) 
					\end{itemize}
					
				\paragraph{Stato di un processo}		
					\begin{itemize}
						\item \textbf{Running} È in esecuzione sul processore.
						\item \textbf{Ready} In attesa di essere eseguito dal processore.
						\item \textbf{Blocked} In stato di block, il processo sta esegundo qualche operazione (\textit{es: I/O}).
					\end{itemize}
					
				\paragraph{Strutture dati} Il sistema operativo deve tenere traccia delle informazioni fondamentali di un processo per poter ripristinare l'esecuzione di un processo interrotto. Esse sono: 
					\begin{itemize}
						\item Porzioni di memoria coinvolte.
						\item Valori dei registri di CPU usati dal processo.
						\item Stato dei dispositivi di I/O usati dal processo.
					\end{itemize}
					Questi dati sono organizzati in strutture chiamate \textbf{Process Control Block (PCB)}, salvate in un per-process \textbf{kernel stack}, il quale risiede nel kernel space.
					
			\subsubsection{Process API}
				
				La creazione di un processo avviene tramite la \texttt{fork()}, la quale genera un processo identico a quello in esecuzione. Tale processo prende il nome di padre, quello generato viene chiamato figlio. L'esecuzione del processo figlio parte dall'istruzione successiva alla \texttt{fork()}. La \texttt{fork()} ritorna al figlio 0, al padre il \textbf{PID} del figlio e \textbf{-1} in caso di errore. Il processo figlio avrà il \textbf{proprio} address space, registri, PC, ecc\dots   \\
				
				La \texttt{wait()} è una funzione che forza il padre ad aspettare che il processo figlio termini la propria esecuzione. Senza, l'output potrebbe essere \textbf{non-deterministico} e potrebbero crearsi processi orfani o zombie. Esiste anche la \texttt{waitpid} che viene usata se si ha a che fare più di un figlio.\\
				
				Per eliminare un processo esiste la funzione \texttt{kill()}. Solo il padre può distruggere il figlio. Ciò può portare alla creazione di processi \textbf{zombie} (processi terminati la cui \textbf{PCB} è ancora in memoria). \\
				
				La \texttt{exec()} serve per generare un processo che fa qualcosa di diverso da quello padre. \texttt{exec(nome\_programma, arg)} prende il nome di un eseguibile e alcuni argomenti, carica il codice e i dati statici di quell'eseguibile, sovrascrivendo il code segment corrente all'interno del PCB del figlio. Heap, stack e altre parti di memoria vengono re-inizializzate. Rimane la relazione padre-figlio.
				
		\subsection{Context Switch}
		
			\subsubsection{Shell}
				
				Come mai \texttt{fork()} ed \texttt{exec()} sono due system call separate? Per rispondere introduciamo la \textbf{shell}.
				
				La shell è un programma del sistema operativo \texttt{Unix }il cui compito è riconoscere ed eseguire altri programmi; si può dire che essa sia il genitore di tutti i processi che vengono mandati in esecuzione. Nello specifico, essa esegue una \texttt{fork()}, cambia il file descriptor se richiesto, ed infine invoca la \texttt{exec()}. Poi si mette in attesa che il programma abbia terminato prima di tornare in attesa di istruzioni. Esistono due tipi di shell, grafica (\textit{terminale}) e interattiva (\textit{aprire programmi col mouse}). 
				
				La separazione di \texttt{fork()} ed \texttt{exec()} è dovuta alla presenza della shell, con la quale possiamo andare ad effettuare alcune modifiche dopo la \texttt{fork()} e prima dell'\texttt{exec()}, come ad esempio la sostituzione del file descriptor. 
				
				$$\texttt{\$> wc file.c > n.txt}$$
				
				La shell esegue la \texttt{fork()} per poter mandare in esecuzione il programma \texttt{wc}. Prima di sostituire il codice del padre all'interno del PCB del figlio, sostituisce il file descriptor relativo allo standard output con n.txt. Successivamente esegue l'\texttt{exec()} producendo l'output desiderato all'interno di n.txt. Queste manipolazioni non sarebbero possibili se \texttt{fork()} ed \texttt{exec()} fossero un'unica system call perchè non si avrebbe accesso al PCB del figlio prima dell'exec().
				
			\subsubsection{Direct execution}
			
				Il concetto di direct execution è semplice: il programma viene eseguito direttamente sulla CPU fisica.
				
				Quando il sistema operativo desidera iniziare l'esecuzione di un programma, viene fatto quanto segue: 
				
				\begin{itemize}
					\item Crea una entry nella lista dei processi.
					\item Alloca la memoria per il programma.
					\item Carica il programma in memoria.
					\item Imposta lo stack con \texttt{argc/argv}.
					\item Pulisce i registri.
					\item Esegue la chiamata a \texttt{main()}.\\
					Si ha un salto dalla zona kernel al \texttt{main}. Il processo a questo punto deve:
					\item Eseguire il codice del \texttt{main()}.
					\item Ritornare dal main a fine esecuzione.\\
					Dal processo si torna alla zona kernel. Il sistema operativo infine:
					\item Rimuove la entry dalla lista dei processi.
				\end{itemize}
				
				Tuttavia la direct execution solleva alcune problematiche:
				
				\begin{itemize}
					\item Il sistema operativo non può assicurarsi che un programma in esecuzione non faccia qualcosa che non dovrebbe fare.
					\item Il sistema operativo non può fermare un processo in esecuzione.
				\end{itemize}
				
				Il primo problema si risolve con l'introduzione dello \textbf{user mode}. Il codice che viene eseguito in questa modalità di elaborazione è limitato in termini di istruzioni eseguibili. Nasce quindi anche la \textbf{kernel mode}, modalità in cui opera il sistema operativo e che consente di eseguire tutte le istruzioni privilegiate.
				
				Per permettere ad un processo di eseguire istruzioni privilegiate vengono introdotte delle \textbf{system call}. Per eseguirle, un programa deve eseguire un'istruzione \textbf{trap} (\textit{interrupt via software}).	Questa istruzione salta nel kernel, aumenta i privilegi a kernel mode, esegue le operazioni privilegiate e ritorna al processo scalando i privilegi tramite un'istruzione \textbf{return-from-trap}. Durante questo procedimento bisogna assicurarsi di salvare i registri del chiamante. Per sapere dove la trap deve saltare, il kernel imposta una \textbf{trap table} al boot time. Non è il processo utente a specificare l'indirizzo dei \textbf{trap handlers} perchè potrebbe saltare ovunque nel sistema.\\
				Per specificare la system call, generalmente viene assegnato un \textbf{system-call-number} che solitamente viene inserito in un registro appropriato.
				
			\subsubsection{Switch tra processi}
				
				\paragraph{Cooperative approach} Soluzione via software che consiste nel programmare il processo in modo che, dopo un certo numero di secondi di utilizzo della CPU, il comando torni al sistema operativo. Il problema è che se vengono creati loop infiniti nel programma, la CPU non verrebbe mai condivisa.
				
				\paragraph{Time interrupt} Soluzione via hardware che consiste nel creare una nuova componente che genera un segnale elettrico (\textbf{time interrupt}) dopo un certo lasso di tempo. Ci sarà quindi un orologio interno che invierà un segnale al piedino del microprocessore. L'hardware deve inoltre fermare l'esecuzione del processo corrente, salvarne lo stato per dare il controllo allo \textbf{scheduler}, che nel caso decidesse di cambiare processo, farà eseguire al sistema operativo codice a basso livello che prende il nome di \textbf{context switch}. 
				
				\paragraph{Context switch} Ciò che deve fare il sistema operativo è salvare alcuni valori dei registri per il processo in corso di esecuzione (\textit{nel kernel stack}) e ripristinarne altri per il processo scelto. Viene eseguita una return-from-trap per mandare in esecuzione il processo scelto.\\
				Interrupt, system call ed eccezioni sono eventi che inducono il mode switch. 

		\subsection{Scheduling policy}
			Dati $n$ processi, a quale assegno il processore?
			La scelta è fatta dallo \textbf{scheduler}, un modulo del sistema operativo che implementa una politica decisionale.
			\paragraph{CPU burst} è l'intervallo di tempo in cui viene usata intensamente la CPU. 
			\paragraph{I/O burst} è l'intervallo di tempo in cui viene usato intensamente I/O.
			\paragraph{CPU bound} processi con CPU burst lunghi, ad esempio compilatori, simulatori, calcolo del tempo, ecc\dots
			\paragraph{I/O Bound} processi con I/O burst lunghi, ciò comporta maggiore interattività con l'utente.
			\paragraph{Stato di IDLE} è lo stato in cui è una risorsa accesa e funzionante ma non utilizzata. \\	
							
			Un processo in esecuzione si trova o in CPU burst o in I/O burst. 			
			Lo scheduler, per essere efficiente, deve ottimizzare l'uso delle risorse in modo tale che, se la CPU è occupata con l'esecuzione di un processo, i dispositivi di I/O lo sono con un altro e viceversa. L'ottimizzazione della CPU viene dunque portata mediante lo scheduler. Per valutare la bontà di un algoritmo di scheduling si devono introdurre delle metriche di valutazione.
			$$T_{turnaround} = T_{termine} - T_{arrivo}$$
			$$T_{response} = T_{first-exec} - T_{arrivo}$$
			$$T_{wait} = T_{turnaround} - T_{job}$$
				
			\subsubsection{Algoritmo FIFO} 
				L'algoritmo FIFO (\textit{First In First Out}) mette in esecuzione il primo processo arrivato. Il problema a cui può portare questo algoritmo è l'\textbf{effetto convoglio}, ovvero quando un certo numero di piccoli consumatori di una risorsa vengono messi in coda dietro un enorme consumatore. 
				
			\subsubsection{Algoritmo SJF}
				L'algoritmo SJF (\textit{Shortest Job First}) mette in esecuzione il processo con CPU burst minore. In questo modo si evita l'effetto convoglio, ma solo se i processi arrivano allo stesso istante.
					
			\subsubsection{Algoritmo STCF}
				L'algoritmo STCF (\textit{Shortest Time to Completion First}) ogni volta che arriva un processo, lo compara il processo in esecuzione e lascia il processore a quello che ha CPU burst minore.\\
				
			SJF e STCF funzionano molto male per quanto riguarda il tempo di risposta (spesso possono indurre anche al verificarsi della starvation). Inoltre non conoscono a priori il CPU burst di un processo, perciò sono solo algoritmi teorici.
				
			\subsubsection{Round Robin}
				L'algoritmo \textbf{Round Robin} assegna un \textbf{quanto di tempo} ad ogni processo. Viene inizializzato un timer che, una volta arrivato a zero, forza un context switch. Il quanto di tempo va scelto bene, altrimenti si hanno troppi context switch se è troppo piccolo, o degenera in FIFO se è troppo grande.
			
			
		\subsection{Multilevel feedback scheduler}
			Il problema che \textbf{MLFQ} (\textit{MultiLevel Feedback Queue}) cerca di risolvere è: 
			\begin{itemize}
				\item Ottimizzare il $T_{turnaround}$.
				\item Aumentare l'interattività utente/sistema, minimizzando il $T_{response}$.
			\end{itemize}
			L'approccio che si usa consiste nell'avere un certo numero di \textbf{code} distinte, ognuna assegnata ad un diverso \textbf{livello di priorità}. MLFQ sfrutta i diversi livelli di priorità per decidere quale processo eseguire: viene scelto quello all'interno della coda di priorità maggiore. Se ci sono più processi all'interno di una certa coda, viene usato \textbf{RR}.
			\begin{itemize}
				\item 1. If priority(A) $>$ priority(B), A runs (B doesn't).
				\item 2. If priority(A) = priority(B), A \& B run in RR.
				\item 3. Quando un processo entra nel sistema, viene posizionato nella coda di priorità massima.
				\item 4a. Se un processo utilizza tutto il lasso di tempo a disposizione durante l'esecuzione, la sua priorità viene ridotta.
				\item 4b. Se un processo libera la CPU prima di terminare il lasso di tempo a disposizione, il livello di priorità rimane invariato.
				\item 5. \textbf{Priority boost }Dopo un certo periodo di tempo, tutti i processi vengono spostati nella coda di priorità più alta. (\textit{Evita la starvation dei long running jobs e il monopolio della CPU se qualche processo la rilascia poco prima del lasso di tempo.})
			\end{itemize}
			
			\subsubsection{Better accounting}
				La  scelta del tempo è cruciale, se settato troppo grande, i long running jobs potrebbero ancora andare in starvation, se impostato troppo piccolo, i processi interattivi potrebbero non avere una porzione adeguata dela CPU. 
				Per evitare che possa essere raggirato l'algoritmo di scheduling, lo scheduler tiene tracia di quanto tempo ha consumato un processo in un certo livello di \textbf{MLFQ}. Le regole 4a e 4b diventano: \\
				\begin{itemize}
					\item 4. Una volta che un processo ha usato il tempo a disposizione in un certo livello (indipendentemente da quante volte ha rilasciato la CPU), la sua priorità viene ridotta.
				\end{itemize}								

		
		\subsection{Address space}
			Un programma per essere eseguito deve risiedere in memoria. Essa può essere usata implicitamente (\textbf{stack:} \texttt{int x}) o esplicitamente (\textbf{heap:} \texttt{int *x = malloc(sizeof(int))}). Lo stack è gestito autonomamente, lo heap è gestito dal programmatore attraverso opportune funzioni (\texttt{malloc, realloc, free, \dots}), per cui non si conosce a priori la dimensione.
			
			\subsubsection{Memory API}
				\begin{itemize}
					\item \texttt{malloc()} Riceve in input un argomento di tipo \texttt{size\_t} (numero di bytes), se ha successo restituisce un puntatore all'inizio della zona allocata nello \textbf{heap}, se fallisce restituisce NULL.
					\item \texttt{free()} Riceve in input un puntatore, la grandezza della regione da liberare viene tenuta nella libreria \texttt{memoryallocation}.
				\end{itemize}
				
				La system call per la gestione diretta della memoria è \texttt{int brk(void *addr)}
				
			\subsubsection{Memory errors}
				\begin{itemize}
					\item \textbf{Dimenticarsi di allocare la memoria.} È da patchare il fatto che si possa indurre un \texttt{segfault} in modo tale da poter accedere al core dump della memoria e vedere dati sensibili (\textbf{attacchi core-dump}). È necessario eliminare questi dati dopo il loro utilizzo. 
					\item \textbf{Non allocare abbastanza memoria.} Può portare a vulnerabilità come il \textbf{buffer overflow}.
					\item \textbf{Dimenticarsi di inizializzare memoria allocata.} Potrebbero esserci valori come 0 o valori random.
					\item \textbf{Dimenticarsi di liberare la memoria.} Il \textbf{memory leak} può portare ad un esaurimento della memoria disponibile.
					\item \textbf{Liberare la memoria prima di aver finito di usarla.} Questo errore è chiamato \textbf{dangling pointer}, può causare un crash o la sovrascrittura di memoria valida.
					\item \textbf{Liberare la memoria più di una volta.} Problema noto come \textbf{double free}, il risultato è indefinito, la libreria \texttt{memory-allocation} potrebbe confondersi e fare cose strane. I crash sono la cosa più comune.
					\item \textbf{Chiamata di \texttt{free()} incorretta.} La funzione si aspetta un puntatore prodotto in precedenza da una \texttt{malloc()}. Quando viene passato alla \texttt{free }un valore diverso, possono succedere cose brutte e pericolose.
				\end{itemize}
				
			\subsubsection{Virtualizzazione della memoria}
				Con l'avvento della \textbf{multiprogrammazione} la memoria diviene una risorsa condivisa, bisogna iniziare a far fronte a tutte le problematiche che ciò comporta.
				\begin{itemize}
					\item \textbf{Protezione} un processo non può invadere lo spazio di un altro.
					\item \textbf{Interattività} Ci devono essere molti processi in esecuzione.								
				\end{itemize}
				Il meccanismo di astrazione che si vuole implementare prende il nome di \textbf{address space}, esso è il punto di vista di un processo sulla memoria del sistema, ovvero l'astrazione che il sistema operativo gli fornisce.
				
				Gli obiettivi della virtualizzazione della memoria sono riassunti come segue:
				\begin{itemize}
					\item \textbf{Trasparenza.} Il programmatore scrive il codice indipendentemente dalla grandezza della memoria.
					\item \textbf{Efficienza.} Il meccanismo di virtualizzazione non deve avere overhead troppo elevato.
					\item \textbf{Protezione.} Bisogna proteggere i processi da altri processi, dal sistema operativo, e viceversa.
				\end{itemize}
				
			\subsubsection{Mapping}
				Il \textbf{mapping} consiste nel trovare una corrispondenza fra indirizzo logico e indirizzo fisico. Nei sistemi \textbf{monoprogrammati} ciò era facile poichè ogni programma veniva mappato a partire dall'indirizzo \texttt{64KB} fino alla fine. Il compilatore assegnava ai programmi indirizzi costanti. Nel caso della \textbf{multiprogrammazione} invece, il compilatore assegna indirizzi preliminarli al programma, i quali  vengono successivamente rilocati. 
			
			\subsubsection{Base e Bound}
				Questa tecnica di mapping utilizza due registri, \textbf{base} e \textbf{bound}.
				Assunzioni: 
				\begin{itemize}
					\item Il programma viene caricato in locazioni contigue di memoria. (Un programma da \texttt{32KB} verrà caricato in \texttt{32KB} locazioni adiacenti)
					\item L'indirizzo logico è sempre minore dell'indirizzo fisico.
				\end{itemize}
				Mediante la rilocazione siamo in grado di calcolare l'indirizzo fisico come segue: 
				$$\texttt{indirizzo fisico = indirizzo logico + Base}$$
				\textbf{Base} è un registro contenente il punto di partenza (indirizzo fisico) del programma. \textbf{Bound} è il registro limite. Se un processo prova a saltare in zone di un altro processo viene generato un errore di segmentazione.
				
			\subsubsection{MMU}
				MMU sta per \textbf{Memory Managment Unit} ed è una componente hardware per la rilocazione degli indirizzi. L'input è un indirizzo logico prodotto dalla CPU, l'output è l'indirizzo fisico. Generalmente questa traduzione viene fatta a runtime. Prima di eseguire l'istruzione a cui sto puntando, l'indirizzo logico viene tradotto in indirizzo fisico (\textbf{rilocazione dinamica}).\\
				Ore che abbiamo la rilocazione dinamica, il sistema operativo deve fare le seguenti cose per implementare la memoria virtuale: 
				\begin{itemize}
					\item Quando un nuovo processo viene creato, il sistema operativo dovrà cercare in una struttura dati (spesso chiamata \textbf{free list}) spazio libero per il nuovo address space e marcarlo come in uso.
					\item Quando un processo termina, deve riabilitare tutta la memoria allocata per il processo all'interno della free list e pulire ogni struttura dati associata ad esso.
					\item Quando avviene un context switch deve salvare nel PCB i registri base e bound e ripristinare quelli del nuovo processo. 
					\item Quando un processo viene fermato è possibile muovere un address space da una locazione di memoria a un'altra. Basta deschedularlo, copiare l'address space dalla locazione corrente a quella nuova e infine aggiornare il registro \textbf{base}.
				\end{itemize}
				
				Il sistema operativo deve fornire degli \textbf{exception handler}. Per esempio, se un processo prova ad accedere a memoria al di fuori del suo \textbf{bound}, la CPU deve sollevare un'eccezione. 
				
		\subsection{Segmentazione}
			
			\subsubsection{Binding}
				
				Durante il processo di rilocazione vengono cambiati tutti gli indirizzi del programma per evitare che vadano fuori dallo spazio di indirizzamento previsto. Il \textbf{binding} è l'operazione che viene fatta per modificare gli indirizzi. Può essere: 
				\begin{itemize}
					\item \textbf{Early binding.} Rilocazione degli indirizzi fatta a \textbf{compile time}. Il compilatore deve conoscere la posizione di partenza del programma in memoria, ma funziona solo quando il compilatore genera direttamente il codice assoluto (\textit{sistemi embedded, monoprogrammati, \dots}).
					\item \textbf{Delayed binding.} La rilocazione degli indirizzi viene fatta durante il trasferimento del programma da disco a memoria (\textit{operazione svolta dal sistema operativo prima dell'introduzione dell'MMU}).
					\item \textbf{Late binding.} La rilocazione degli indirizzi viene fatta immediatamente prima di eseguire l'istruzione corrente, quindi a \textbf{runtime}. Per implementare questa tecnica serva l'MMU. 
				\end{itemize}
				
			\subsubsection{Segmentazione}
				
				Con la tecnica base e bound, c'è dello spazio potenzialmente non utilizzato tra lo stack e lo heap. L'idea alla base della \textbf{segmentazione} è quella di dividere il programma in \textbf{segmenti} che possono essere caricati in porzioni di memoria differenti siccome ad ognuno di essi è associata una coppia base-bound. I segmenti sono inseriti in modo indipendente all'interno della memoria fisica, in questo modo siamo in grado di evitare gli sprechi. Questo risparmio di memoria, tuttavia, complica notevolmente l'MMU, la quale deve gestire più segmenti presenti all'interno della memoria (ogni processo ha tre segmenti).\\
				Il meccanismo funziona come segue:
				\begin{itemize}
					\item \textbf{Input:} indirizzo logico $B$ (prodotto dal compilatore).
					\item Individua il segmento $s$ di appartenenza dell'indirizzo $B$.
					\item Calcola l'offset $k$ sottraendo all'indirizzo virtuale l'indirizzo di partenza (logico) del segmento ($k = B$ - indirizzo iniziale di $s$)
					\item Viene calcolato l'indirizzo fisico sommando $k$ e il base register (Indirizzo fisico = $Base(s)+k$)
				\end{itemize}
				Se un processo cerca di produrre un indirizzo illegale, l'hardware rileverà che l'indirizzo è out of bounds, trap nel sistema operativo, il quale terminerà il processo (\textbf{segmentation fault}).\\
				L'hardware per conoscere il segmento e l'offset taglia l'address space in segmenti basati sui primi bit dell'indirizzo virtuale (\textbf{approccio esplicito}). Nell'\textbf{approccio implicito} invece l'hardware determina il segmento in base a come è formato l'indirizzo. Se, ad esempio, l'indirizzo è stato generato dal program counter, appartiene al code segment; se è dello stack o del base pointer, deve appartenere al segmento stack. Ogni altro indirizzo viene interpretato come parte del segmento heap.
			
			\subsubsection{Stack}
				Siccome lo stack cresce al contrario, invece dei soli valori base e bound, l'hardware ha bisogno di sapere in quale direzione cresce il segmento (un bit settato a 1 se il segmento cresce positivamento, 0 negativamente). Il controllo del bound register viene fatto in valore assoluto.
				
			\subsubsection{Permessi}
				\paragraph{Code sharing. }Per risparmiare memoria, a volte è  utile condividere certi segmenti tra gli address spaces. Per supportare la condivisione abbiamo bisogno di \textbf{protection bits} da parte dell'hardware. Vengono aggiunti solamente pochi bit per segmento, a indicare quando un programma può leggerne, scriverne o eseguirne il codice contenuto. 
				
			\subsubsection{Coarse grained and fine grained}
				Gli esempi visti fin'ora utilizzavano la tecnica \textbf{coarse grained} (poche fette relativamente grandi). Alcuni dei primi sistemi erano più flessibili e permettevano che gli address spaces consistessero in un gran numero di piccoli segmenti, questo concetto era espresso come segmentazione \textbf{fine grained}. Ciò richiede un ulteriore supporto hardware, una \textbf{segment table} all'interno della memoria.
				
			\subsubsection{Frammentazione} 
				La segmentazione solleva un numero di nuove problematiche:
				\begin{itemize}
					\item Cosa dovrebbe fare il sistema operativo a fronte di un context switch? I segment registers devono essere salvati e ripristinati. 
					\item Come viene gestito lo spazio libero in memoria fisica? Quando un nuovo address space viene creato, il sistema operativo deve essere in grado di trovare lo spazio in memoria fisica per i suoi segmenti. 	
				\end{itemize}				 
				Il problema generale è che la memoria fisica consuma velocemente piccoli spazi liberi, rendendo difficile l'allocazione di nuovi segmenti o la crescita di quelli già esistenti. Questo problema è noto come \textbf{frammentazione esterna}. Si può risolvere con la \textbf{deframmentazione}, compattando la memoria fisica e riarrangiando i segmenti esistenti, copiando i dati dei segmenti in una regione contigua di memoria e cambiando il valore dei loro segment registers. Questa operazione è piuttosto complessa e dispendiosa oltre che bloccante. Un approccio più semplice è quello di usare un algoritmo per la gestione della \textbf{free-list} che tenta di mantenere un elevato spazio disponibile contiguo in memoria. Purtroppo però la frammentazione esisterà sempre a prescindere da quanto buono sia l'algoritmo per minimizzarla.
				
		\subsection{Paginazione}
			La \textbf{paginazione} nasce per gestire in modo ottimale lo spazio libero in memoria e l'address space di un programma.
			Consiste nel tagliare gli spazi in fette di una certa dimensione. Anzichè dividere l'address space di un processo in segmenti, esso viene diviso in unità di dimensione fissata, ognuna delle quali è chiamata pagina.\\
			Vediamo la memoria fisica come un array di slots di dimensione fissata, chiamati \textbf{page frames}. Ogni frame può contenere una singola pagina di memoria virtuale. Ciò porta ad alcuni vantaggi: 
			\begin{itemize}
				\item \textbf{Flessibilità.} Il sistema sarà in grado di supportare l'astrazione dell'address space efficacemente, a prescindere da come un processo ne fa uso. Non vogliamo, ad esempio, dover fare assunzioni riguardo la direzione di crescita dello heap e dello stack e come vengono usati.
				\item \textbf{Semplicità} della gestione dello spazio libero. Per esempio, supponiamo che il sistema operativo desideri  inserire il nostro addess space da \texttt{64B} in memoria fisica. Siccome i programmi sono divisi in pagine di dimensione fissata, il problema della segmentazione viene ridotto di molto visto che, siccome il sistema operativo tiene traccia della free list, gli basta semplicemente prendere il primo frame disponibile e assegnarlo a una pagina.
			\end{itemize}
			Per memorizzare dove ogni pagina virtuale dell'address space è posizionata in memoria fisica, il sistema operativo tiene una struttura dati per  ciascuno processo nota come \textbf{page table}. Il ruolo principale della page table è di memorizzare, per ogni pagina virtuale dell'address space, il corrispondente frame fisico.	
			
			\subsubsection{Address translation}
				Per tradurre l'indirizzo virtuale generato da un processo, dobbiamo per prima cosa dividerlo in \textbf{Virtual Page Number (VPN)} e \textbf{offset}.
				Siccome si conosce la dimensione di ciascuna pagina, si può dividere l'indirizzo virtuale in:
				\begin{itemize}
					\item \textbf{VPN:} Bit più significativi che fanno da indice per accedere alla page table del processo per trovare il frame fisico corrispondente (\textbf{PFN}).
					\item \textbf{Offset:} Bit che servono per indirizzare la grandezza di una pagina.
				\end{itemize}
				A questo punto si traduce l'indirizzo virtuale in fisico sostituendo il \textbf{Physical Frame Number (PFN)} al VPN.
			
			\subsubsection{Page tables}
				Le page tables possono essere terribilmente grandi. Per esempio, immaginiamo un address space da \texttt{32 bit} con pagine da \texttt{4KB}. L'indirizzo virtuale sarà diviso in \texttt{20 bit} di VPN e \texttt{12 bit} di offset. \texttt{20 bit} di VPN implicano $2^{20}$ possibili traduzioni per ogni processo. Assumendo di aver bisogno di \texttt{4B} per \textbf{page table entry (PTE)} per mantenere la traduzione fisica più ogni altra informazione utile otteniamo \texttt{4MB} di memoria necessari per ogni page table. Con 100 processi in esecuzione, questo significa che il sistema operativo avrà bisogno di \textbf{400MB} di memoria. 
				\paragraph{Cosa contiene una page table?} La page table è sempicemente una struttura dati usata per mappare gli indirizzi virtuali in indirizzi fisici. La forma più semplice è chiamata \textbf{page table lineare} che è semplicemente un array. Il sistema operativo indicizza l'array con il VPN e consulta la PTE a quell'indice per trovare il PFN desiderato.\\ 
				Ogni PTE contiene diversi bit:
				\begin{itemize}
					\item \textbf{Valid bit.} Indica quando una particolare traduzione è valida. Per esempio, quando un programma inizia l'esecuzione, avrà code e heap a un'estremità del suo spazio di indirizzamento e lo stack dall'altra. Tutto lo spazio non utilizzato in mezzo sarà marcato come invalido e se il processo tenterà di accedervi, verrà generata una trap al sistema operativo che lo terminerà. È cruciale per supportare un address space sparso. 
					\item \textbf{Protection bits.} Indicano quando una pagina può essere letta, scritta o eseguita. Accedere a una pagina in modo non consentito da questi bit genererà una trap nel sistema operativo, il quale terminerà il processo.
					\item \textbf{Present bit.} Indica se la pagina in questione è in memoria fisica o su disco. Consente al sistema operativo di swappare le pagine liberando la memoria fisica.
					\item \textbf{Dirty bit.} Indica se la pagina è stata modificata da quando risiede in memoria.
					\item \textbf{Reference bit.} Viene usato per tenere traccia se una pagina è stata acceduta da quando risiede in memoria. 
				\end{itemize}
			
			\subsubsection{Quanto è lenta la paginazione?}
				Per ogni riferimento a memoria (sia per prelevare un'istruzione che per un load o store esplicito), la paginazione ne necessita uno aggiuntivo per prelevare la traduzione dalla page table. I riferimenti a memoria aggiuntivi sono costosi e in questo caso rallenteranno il processo di un fattore pari a due o più.
				
		\subsection{Translation Lookaside Buffer}
			Siccome le informazioni di mappatura risiedono generalmente in memoria fisica, la paginazione richiede un accesso aggiuntivo per ogni indirizzo virtuale generato dal programma. L'obbiettivo è snellire la tecnica introdotta, cercando di \textbf{diminuire il numero di accessi a memoria fisica }(alla page table). Viene aggiunta alla MMU una cache hardware delle traduzioni virtual-to-physical più popolari chiamata \textbf{translation lookaside buffer  o TLB}. Per ogni indirizzo virtuale, l'hardware controlla per prima cosa il TLB per vedere se la traduzione desiderata è presente al suo interno. 
			\begin{lstlisting}[style=CStyle]
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN);
if (Success == True){	//TLB HIT
	if (CanAccess(TlbEntry.ProtectBits == True){
		Offset = VirtualAddress & OFFSET_MASK;
		PhysAddr = (TlbEntry.PFN << SHIFT) | Offset;
		Register = AccessMemory(PhysAddr);				
	}
	else
		RaiseException(PROTECTION_FAULT);
}	
else{						//TLB MISS
	PTEAddr = PTBR + (VPN * sizeof(PTE));	
	PTE = AccessMemory(PTEAddr);
	if(PTE.Valid == False)
		RaiseException(SEGMENTATION_FAULT);
	else if (CanAccess(PTE.ProtectBits) == False)
		RaiseException(PROTECTION_FAULT);
		else{
			TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits);
			RetryInstruction();
		}								
}			\end{lstlisting}
			L'algoritmo che l'hardware segue funziona in questo modo: 
			\begin{itemize}
				\item Estrae il VPN dall'indirizzo virtuale.
				\item Controlla se il TLB contiene la traduzione per il VPN. Se così fosse, abbiamo un \textbf{TLB hit}, la traduzione è cioè contenuta in cache.
				\item Se la CPU non trova la traduzione nella TLB abbiamo un \textbf{TLB miss}. L'hardware accede alla page table per trovare la traduzione e, assumendo che l'indirizzo virtuale generato dal processo sia valido e accessibile, aggiorna il contenuto del TLB con la nuova entry. Queste operazioni sono parecchio costose.
				\item Una volta che il TLB è aggiornato, l'hardware riprova l'istruzione, ottenendo un TLB hit.
			\end{itemize}
			
			\subsubsection{Performance  e località}
				Il TLB migliora le performance grazie al \textbf{principio di località}. Esso si divide in:
				\begin{itemize}
					\item \textbf{Spaziale.} Se la CPU sta eseguendo un'istruzione presente in memoria, vuol dire che con molta probabilità le prossime istruzioni da eseguire si troveranno fisicamente nelle vicinanze di quella in corso.
					\item \textbf{Temporale.} Se accedo all'istruzione 100 al tempo $t_0$, con molta probabilità acederò nuovamente ad essa negli istanti di tempo successivi. 
				\end{itemize}
			
			\subsubsection{TLB miss}
				Chi gestisce un TLB miss? Ci sono due possibili risposte:
				\begin{itemize}
					\item \textbf{Hardware.} L'HW deve sapere la posizione delle page tables in memoria (attraverso il page table register), oltre al loro formato esatto. In presenza di un miss, l'HW deve accedere alla page table, trovare la PTE corretta, estrarre la traduzione desiderata, aggiornare il TLB con la pagina contenente l'indirizzo fisico ricercato e riprovare l'istruzione.
					\item\textbf{Software (S.O).} Al verificarsi di un TLB miss, l'hardware solleva un eccezione per mettere in pausa il flusso corrente di istruzioni, aumenta i privilegi a livello kernel e salta a un trap handler. Questo trap handler è codice scritto all'interno del sistema operativo, il cui scopo è la gestione esplicita dei TLB misses. Il codice cercherà la traduzione nella page table, userà "speciali" istruzioni privilegiate per aggiornare il TLB e, infinie, eseguirà la \textbf{return-from-trap}. A questo punto, l'hardware riproverà l'istruzione (TLB hit).
				\end{itemize}
				\paragraph{TLB return from trap} In questo caso, quando si torna da una TLB miss-handling trap, l'hardware deve ripristinare l'esecuzione dall'istruzione che aveva causato la trap nel sistema operativo.
				
				Quando il TLB miss-handler è in esecuzione, il sistema operativo deve essere molto attento a non causare una catena infinita di TLB misses. Se ho un miss, viene generata un'eccezione. Bisogna fare un context switch per permettere al S.O. di gestire l'evento. Per mandarlo n esecuzione bisogna mettere l'indirizzo del TLB miss-handler nel PC. Questo indirizzo tuttavia, come tutti gli altri, viene passato all'MMU. Quest'ultima lo cerca nel TLB, ottenenedo un miss. Parte quindi un loop. La soluzione che viene adottata per risolvere questo problema consiste nel tenere il miss handler all'interno del TLB.
				
				
			\subsubsection{TLB - contenuto}
				Una address-translaion cache tipica potrebbe avere 32, 64 o 128 entries ed essere ciò che viene chiamato \textbf{fully associative}. Ciò significa che una traduzione potrebbe essere ovunque nel TLB e l'hardware dovrà cercare in parallelo fino a trovare la traduzione desiderata. Una entry del TLB ha il seguento aspetto: \texttt{VPN | PFN | other bits}.\\
				Tra gli other bits generalmente ci sono il \textbf{valid bit}, i \textbf{protection bits}, \dots
				
			\subsubsection{TLB - Context Switch}
				Il TLB contiene traduzioni virtual to physical che sono valide per il processo in esecuzione ma prive di significato per gli altri. Bisogna assicurarsi che quando cambiamo processo, il processo che sta per essere eseguito non usi le traduzioni di quello precedente. Un approccio semplice ma inefficace è fare un \textbf{flush} (impostando tutti i valid bit a 0) del TLB a fronte di un context switch. Ogni volta che un processo verrà eseguito, incapperà in TLB misses.\\
				Per ridurre questo overhead, alcuni sistemi aggiungono un supporto hardware per abilitare la condivisione del TLB attraberso context switcher. In particolare alcuni sistemi hardware forniscono un campo \textbf{Address Space Identifier} (ASID) nel TLB. 
				
		\subsection{Multi Level Page Tables}		
			Le page tables sono grandi e consumano troppa memoria. 
			
			\subsubsection{Bigger pages}
				Una possibile soluzione è quella di fare pagine più grandi. Il problema è che questo comporta a sprechi di spazio all'interno delle pagine stesse (\textbf{frammentazione interna}). La memoria si riempie subito di pagine contenenti parecchio spazio vuoto.
			
			\subsubsection{Paginazione e segmentazione}
				Assumiamo di avere un address space nel quale la porzione usata da stack e heap è piccola. Per esempio, usiamo uno spazio di indirizzamento da \texttt{16KB} con pagine da \texttt{1KB}. La page table relativa a questo address space sarà quindi:
				\begin{center} \begin{tabular}{|c|c|c|c|c|}
					\hline					
					PFN & valid & prot & present & dirty\\
					\hline
					10 & 1 & r-x & 1 & 0\\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					23 & 1 & rw- & 1 & 1\\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					- & 0 & \_ & - & - \\
					28 & 1 & rw- & 1 & 1\\
					4 & 1 & rw- & 1 & 1\\
					\hline
				\end{tabular} \end{center}
				Come possiamo osservare dalla figura, la maggior parte della page table non è utilizzata.
				Invece di avere una singola page table per l'intero address space del processo, perchè non averne una per segmento logico? Con la segmentazione avevamo un registro \textit{base} che ci diceva dove ogni segmento risiedeva in memoria fisica e un registro \textit{bound} che ne esprimeva la grandezza. Nel nostro approccio ibrido, abbiamo queste strutture nell'MMU; qui, non usiamo il \textit{base} per puntare al segmento stesso, ma teniamo l'indirizzo fisico della page table di quel segmento. Il registro \textit{bound} è usato per indicare la fine della page table relativa a un segmento.\\
				Nell'hardware, assumiamo che ci siano tre paia di \textit{base/bound}: una per code, heap e stack. In un context switch, questi registri devono essere cambiati per riflettere la locazione delle page tables del nuovo processo in esecuzione. In un TLB miss, l'hardware usa i bits del segmento per determinare quale coppia \textit{base/bound} usare. L'hardware quindi prende il \textit{base} corretto e lo combina col VPN come segue, per formare l'indirizzo della PTE: 
				\begin{lstlisting}[style=CStyle]
SN = (VirtualAddress & SEG_MASK) >> SN_SHIFT
VPN = (VirtualAddress & VPN_MASK) >> VPN_SHIFT
AddressOfPTE = Base[SN] + (VPN * sizeof(PTE)) \end{lstlisting}
				La differenza critica, sta nella presenza di un registro \textit{bound} per segmento. Ogni \textit{bound} contiene il valore della massima pagna valida nel segmento. Se il code segment sta usando le sue prime tre pagine (0, 1 e 2), la page table del segmento avrà solamente tre entries allocate e il bound register sarà impostato a 3. In questa maniera, il nostro approccio ibrido realizza un risparmio di memoria significativo rispetto alla classica page table lineare.\\ 
				
				Purtroppo questo approccio si porta dietro con sè tutti i problemi della segmentazione, e se avessimo ad esempio heap molto grandi e sparsi in memoria, finiremmo con l'avere ancora una volta sprechi per via dele page table. Seconda cosa, il manifestarsi ancora una volta della frammentazione esterna. 
				
			\subsubsection{Multi Level Page Tables}
				Un altro approccio potrebbe essere trasformare una page table lineare in qualcosa di sime a un albero.
				\begin{itemize}
					\item Per prima cosa, viene tagliata la page table in unità page-sized.
					\item Se una pagina di una PTE è invalida, non viene allocata.
					\item Per tenere traccia se una pagina delle page table è valida (e se valida, dove risiede in memoria), usiamo una nuova struttura chiamata \textbf{page directory}.
				\end{itemize}
				Ciò che fa la \textbf{multi-level table} è far scomparire parti della page table lineare e tenere traccia di quali pagine sono allocate.\\
				
				La page directory, consiste in una serie di \textbf{page directory entries (PDE)}, le quali hanno un valid bit e un numero di page frame (\textbf{PFN} - in questo caso rappresenta l'indirizzo di memoria dove è situata una page table). Il bit di valità è un po' diverso, se la PDE è valida significa che almeno una delle pagine della page table a cui la entry punta (via PFN) è valida. 
				\paragraph{Vantaggi:}
				\begin{itemize}
					\item La multi-level table alloca spazio \textbf{solamente per la page table in proporzione all'ammontare di address space in uso} (\textit{se c'è tanto spazio in mezzo tra due pagine utilizzate, vengono comunque allocate solo due pagine}). 
					\item Se implementata correttamente, \textbf{ogni porzione della page table entra ordinatamente in una pagina}, rendendo più facile la gestione della memoria; il sistema operativo prende semplicemente la prossima pagina libera quando ha bisogno di allocare o far crescere una page table.
				\end{itemize}
				Abbiamo aggiunto l'\textbf{indirezione}, che ci permette di posizionare pagine della page table ovunque vogliamo in memoria fisica. Questa tecnica ha un costo: in un TLB miss saranno necessari due caricamenti da memoria per prelevare la traduzione corretta dalla page table (una per la page directory e una per la PTE stessa, \textit{trade off time-space}). Nel caso medio (TLB hit), le performance sono \textbf{identiche }alla page table lineare. Un altro aspetto negativo è la \textbf{complessità}, che sia l'hardware o il sistema operativo a gestire la consultazione delle page tables.
			
			\subsubsection{Più di due pagine}
				Bisogna evitare che la page directory diventi troppo grande, altrimenti l'obiettivo di fare in modo che ogni pezzo della multi-level page table entri in una pagina svanisce. Quando si ha a che fare con pagine piuttosto piccole che lasciano parecchi bit di VPN, è preferibile splittare la page directory stessa in più pagine, aggiungendo un'altra page directory sopra ad essa. 
				
		\subsection{Page Fault e Swap}
			Per supportare address spaces di grandi dimensioni (per permettere ai processi di non preoccuparsi se c'è abbastanza spazio in memoria), il sistema operativo avrà bisogno di posizionare altrove le pagine che non sono largamente richieste.
			
			\subsubsection{Swap space}
				La prima cosa da fare è riservare un po' di spazio su disco per muovere le pagine avanti e indietro. Nei sistemi operativi, ci riferiamo a questa locazione come \textbf{swap space}. La sua dimensione è importante, in quanto determina il numero massimo di pagine di memoria che possono essere usate da un sistema ad un dato istante di tempo.
				
			\subsubsection{Present bit}
				Quando l'hardware guarda nella PTE, potrebbe scoprire che la pagina non è presente in memoria fisica. Il modo in cui l'hardware  (o il sistema operativo in caso di software-managed TLB) determina ciò è attraverso un nuovo \textbf{present bit} in ogni PTE. Se il present bit è a 0, la pagina è da qualche parte su disco. A fronte di un \textbf{page fault}, viene invocato il sistema operativo, il quale manda in esecuzione un \textbf{page-fault handler}.
				
			\subsubsection{Page Fault}
				Se una pagina non è presente, il sistema operativo viene messo al comando per gestire il page fault sia nei sistemi hardware-managed TLB che nei software-managed TLB. Il sistema operativo può usare i bits della PTE relativi al PFN come indirizzo su disco. Quando l'I/O del disco è completato, il sistema operativo aggiorna la page table per marchiare la pagina come presente e aggiorna il campo PFN della PTE e riprova l'istruzione. Questo nuovo tentativo potrebbe generare un TLB miss (è possibile aggiornare anche il TLB a seguito di un page fault per evitare questo scenario). Mentre viene fatto I/O il sistema operativo sarà libero di eseguire altri processi in ready. 
				
			\subsubsection{Memoria piena}
				Il sistema operativo potrebbe voler prima swappare una o più pagine su disco per fare spazio a quelle nuove in procinto di caricare. Il processo di scegliere una pagina da sostituire è noto come \textbf{page replacement policy}. Spostare la pagina sbagliata può avere dei costi elevati in termini di performance (\textit{si può causare una velocità disk-like, 10.000 o 100.000 volte più lento}).\\
				
				A fronte di un page fault, il sistema operativo deve trovare il frame fisico per far risiedere la pagina, e se tale frame non c'è, bisogna aspettare che l'algoritmo di replacement venga eseguito e liberi delle pagine dalla memoria rendendole disponibili per l'utilizzo.
			
			\subsubsection{Replacements}
				Piuttosto che aspettare che si riempa la memoria, il sistema operativo tiene un piccolo ammontare di memoria libera. In molti sistemi, vengono utilizzati un \textbf{high watermark} (HW) e un \textbf{low watermark} (LW) per facilitare la decisione di quando iniziare a sfrattare le pagine. Quando il sistema operativo nota che ci sono meno di LW pagine disponibili, un thread (\textbf{swap deamon}) in background rensponsabile della liberazione della memoria viene eseguito. Il thread sfratta le pagine fino a quando non ce ne sono HW disponibili. 
			
				
		\subsection{Replacement policies}
			Decidere quale pagina (o pagine) sfrattare è incapsulato all'interno della \textbf{politica di replacement} del sistema operativo.
			
			\subsubsection{Cache management}
				È possibile vedere il nostro obiettivo come la massimizzazione del numero di cache hits. Conoscere il numero di cache hits e misses ci permette di calcolare l'\textbf{average memory access time} (AMAT).
				$$AMAT = T_M + (P_{MISS}*T_D)$$
				Dove $T_M$ rappresenta il costo di accesso a memoria, $T_D$ il costo di accesso a disco, e $P_{MISS}$ la percentuale di miss (da 0.0 a 1.0). 
				
			\subsubsection{Optimal replacement policy}
				La politica ottimale di replacement conduce al minor numero di misses in generale. Se dobbiamo sfrattare delle pagine, perchè non selezionare quelle che verranno usate più avanti nel tempo? È un approccio semplice ma difficile da implementare.
				
			\subsubsection{FIFO policy}
				FIFO (\textit{first in first out}) ha un buon punto di forza: è semplice da implementare. Purtroppo non è in grado di determinare l'importanza dei blocchi, se una pagina viene acceduta parecchie volte, FIFO deciderà comunque di sfrattarla.
			
			\subsubsection{Random policy}
				L'algoritmo random, che sceglie una pagina casuale da sostituire, ha proprietà simili al FIFO, è semplice da implementare ma non sceglie intelligentemente i blocchi da sfrattare.
				
			\subsubsection{LFU and LRU }
				Per evitare di sfrattare pagine importanti sfruttiamo il \textbf{principio di località}. Se un processo accede una pagina di recente, è molto probabile che quest'ultima verrà acceduta nuovamente nel futuro prossimo. Un tipo di informazione "storica" che potrebbe essere usata in una politica di page replacement è la \textbf{frequenza}. La politica \textbf{Least Frequently Used} (LFU) sostituisce le pagine usate meno di frequente. Simile è LRU \textbf{Least Recently Used} che sostituisce la pagina usata meno di recente.\\		
				Esistono anche una classe di algoritmi opposti, Most Frequently Used MFU e Most Recently used MRU.
				
			\subsubsection{LRU approssimato}
				Dato che scansionare tutti i tempi per trovare la pagina least recently used è molto costoso, possiamo usare un'approssimazione. L'idea richiede supporto hardware, nella forma di \textbf{use bit}. Questo bit è contenuto in ogni pagina del sistema e ogni volta che una di esse viene riferita (letta o scritta), lo use bit è settato dall'hardware a 1. L'hardware non pulisce mai il bit, è il sistema operativo che ha il compito di settarlo a 0. Ci sono molti modi ma il \textbf{clock algorithm} è un approccio molto semplice e funzionale. Immaginiamo tutte le pagine del sistema arrangiate in una lista circolare. Una \textbf{clock hand} punta a una pagina (non importa quale). Quando deve essere fatta una sostituzione, il sistema operativo controlla se la pagina puntata P ha lo use bit a 1 o a 0. Se a 1 non è un buon candidato per la sostituzione, il bit viene settato a 0 e la clock hand passa alla prossima pagina. L'algoritmo continua fino a quando non trova una pagina con use bit a 0. Se la pagina è \textbf{dirty}, deve essere riscritta su disco prima di essere sfrattata, quindi molti sistemi preferisco pulire pagine \textbf{clean}.
				
			\subsubsection{Trashing}
				Cosa dovrebbe fare il sistema operativo quando la memoria è semplicemente sovraccaricata e la richiesta di memoria dell'insieme dei processi in esecuzione eccede la memoria fisica disponibile? In questi casi il sistema è in costante paginazione (\textbf{trashing}). 
				\begin{itemize}
					\item \textbf{Admission control.} Dato un insieme di processi, un sistema può decidere di non eseguirne un sottoinsieme.
					\item \textbf{Out of memory killer.} Quando la memoria è sovraccarica, questo demone sceglie un processo che sta usando intensamente la memoria e lo termina, riducendo piano piano l'utilizzo della risorsa. (\textit{Linux})
				\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%				
	\newpage	
	\section{Concurrency}
		\subsection{Threads e locks}
			Un \textbf{thread }è un sottoinsieme delle istruzioni di un processo, che può essere eseguito in maniera concorrente con altre parti di esso. L’obiettivo dei threads è quello di rendere più veloce l’esecuzione di un processo. Un programma multi-thread ha più punti di esecuzione (molteplici PCs, da ognuno dei quali vengono prelevate ed eseguite istruzioni). Possono essere visti come processi separati che \textbf{condividono lo stesso address space}. Ogni thread ha il proprio insieme privato di registri. Se ci sono due threads in esecuzione su un singolo processore, per switchare da T1 a T2 deve avvenire un context switch. Invece che il PCB avremo bisogno di un \textbf{Thread Control Blocks} (TCBs) per memorizzare lo stato di ogni thread di un processo. La differenza principale tra thread switch e context switch è che nel primo caso l'address space rimane lo stesso.\\
			Un altra grande differenza tra threads e processi riguarda lo stack. In un processo multi-thread, ogni thread è indipendente e potrebbe chiamare varie routines. Invece di un singolo stack nell'address space ce ne sarà uno per thread (\textbf{thread-local storage}).\\
			
			Utilizzare i thread abilita la sovrapposizione dell'I/O con altre attività all'interno di un singolo programma.
			
			\subsubsection{Thread creation}
				Vogliamo creare un programma che generi due threads. Ogni threads eseguirà la funzione \texttt{mythread()} con argomenti diversi (stringa A o B). Una volta che un thread viene creato, potrebbe venire eseguito subito (dipende dallo scheduler) o essere messo in stato di ready. 
				\begin{lstlisting}[style=CStyle]
#include <stdio.h>
#include <assert.h>
#include <pthread.h>

void *mythread(void *arg) {
	printf("%s\n", (char *) arg);
	return NULL;
}


int main(int argc, char *argv[]) {
	pthread_t p1, p2;
	int rc;
	printf("main: begin\n");
	rc = pthread_create(&p1, NULL, mythread, "A"); assert(rc==0);
	rc = pthread_create(&p2, NULL, mythread, "B"); assert(rc==0);
	// join waits for the threads to finish
	rc = pthread_join(p1, NULL); assert(rc==0);
	rc = pthread_join(p2, NULL); assert(rc==0);
	printf("main: end\n");
	return 0;
} 				\end{lstlisting}
				Il thread principale chiama \texttt{pthread\_join()} che aspetta il completamento di un particolare thread. L'ordine in cui viene eseguito il programma, dipende solo dallo scheduler.
			
			\subsubsection{Dati condivisi}
				La \textbf{race condition} consiste nell'avere più threads che concorrono all'uso della stessa risorsa. Il risultato della computazione \textbf{non è deterministico} in quanto dipende esclusivamente dalle decisioni dello scheduler e da quanto siamo fortunati con i timer interrupts. Una \textbf{sezione critica} è un pezzo di codice che accede alle variabili condivise e non deve essere eseguita simultaneamente da più thread. Abbiamo bisogno della \textbf{mutua esclusione}, la quale garantisce che, se un thread è in esecuzione in sezione critica, agli altri verrà proibilito l'accesso.
				
			\subsubsection{Atomicità}
				Un modo per risolvere il problema potrebbe essere quello di avere istruzioni più potenti che, in un singolo passo, facciano esattamente ciò di cui abbiamo bisogno. In questo caso è l'hardware a garantire l'atomicità, tramite delle \textbf{synchronization primitives}.
				
			\subsubsection{Thread creation}
				\begin{lstlisting}[style=CStyle]
#include <pthread.h>
int pthread_create( pthread_t *thread, const pthread_attr_t *attr, void * (*start_routine) (void*), void * arg ); \end{lstlisting}
				
				\begin{itemize}
					\item \texttt{pthread\_t *thread} è un puntatore a una struttura di tipo \texttt{pthread\_t} che useremo per interagire con i thread.
					\item \texttt{attr} viene usato per specificare ogni tipo di attributo che il thread potrebbe avere. (\textit{Grandezza stack, informazioni riguardanti priorità di scheduling, \dots})
					\item Il terzo argomento è un \textbf{puntatore a funzione} e consiste nel nome della funzione che vogliamo far eseguire al thread creato.
					\item \texttt{arg} è l’argomento che deve essere passato alla funzione che il thread deve eseguire.
				\end{itemize}
				
				I puntatori sono \texttt{void }perchè permettono di passare ogni tipo di argomento facendo semplicemente un cast.
		
			\subsubsection{Thread completion}
				Se vogliamo aspettare il completamento di un thread, dobbiamo chiamare la routine \texttt{pthread\_join()}
				\begin{lstlisting}[style=CStyle]
#include <pthread.h>
int pthread_join( pthread_t thread, void **value_ptr ); \end{lstlisting}
				\begin{itemize}
					\item \texttt{thread} è usato per specificare quale thread stiamo aspettando.
					\item \texttt{**value\_ptr} è un puntatore al valore di ritorno.
				\end{itemize}

				
		\subsection{Locks}
			I lock vengono usati per introdurre la \textbf{mutua esclusione}, permettendo quindi di eseguire atomicamente la sezione critica. Per usare un lock, basta aggiungere il codice necessario attorno alla sezione critica come segue:
			\begin{lstlisting}[style=CStyle]
lock_t mutex; //lock allocato globalmente
...
lock(&mutex);
x = x + 1; 		//sezione critica
unlock(&mutex); \end{lstlisting}				
			
			Un lock è una variabile, e come tale va \textbf{dichiarata e inizializzata}. Un lock, ad un certo istante di tempo, può trovarsi in due stati: \textbf{disponibile} o \textbf{acquisito}. Il funzionamento è questo:
			\begin{itemize}
				\item viene chiamata la routime \texttt{lock()} per acquisire il lock.
				\item Se disponibile, il thread chiamante riceve il lock e può entrare in sezione critica. Se acquisito, il thread chiamante rimarrà bloccato nella routine \texttt{lock()} fino a quando il thread in sezione critica non termina e invoca la \texttt{unlock()}.
				\item Una volta acquisito il lock, un thread può operare in sezione critica. 
			\end{itemize}
			Il nome della libreria \texttt{POSIX} per un lock è \textbf{mutex}. È possibile proteggere la sezione critica con un unico grande lock (\textbf{coarse-grained}) ma è possibile usare svariati lock (\textbf{fine-grained}). Mediante il lock, il programmatore guadagna un po' di \textbf{controllo sullo scheduler}. I locks però devono avere le seguenti proprietà:
			\begin{itemize}
				\item \textbf{Correctnes.} Garantire la mutua esclusione.
				\item \textbf{Fairness.} Evitare che i thread vadano in starvation. Tuttu devono poter accedere alla sezione critica prima o poi.
				\item \textbf{Performance.} L'overhead di time dovuto all'introduzione dei lock non deve minare le performance. 
			\end{itemize}
			Per progettare un lock funzionante, abbiamo bisogno di aiuto da parte dell'hardware e dal sistema operativo.
			\subsubsection{Controlling interrupts}
				Se gli interrupt vengono disabilitati prima di entrare in sezione critica e riabilitati dopo, abbiamo implementato un rudimentale lock.
				\begin{lstlisting}[style=CStyle]
void lock() { DisableInterrupts(); }
void unlock() { EnableInterrupts(); } \end{lstlisting}	
				
				\paragraph{Vantaggi}
					\begin{itemize}
						\item In intel \texttt{CLI} e \texttt{STI} sono già presenti nell'ISA del processore, non dobbiamo quindi apportare modifiche dal punto di vista hardware.
						\item Soluzione molto semplice.
					\end{itemize}

				\paragraph{Svantaggi}
					\begin{itemize}
						\item È necessario avere fiducia nei threads (\texttt{CLI} e \texttt{STI} sono istruzioni privilegiate). Un loop infinito in sezione critica potrebbe causare una catastrofe.
						\item Non funziona bene in presenza di più processori, visto che non siamo in grado di disabilitare gli interrupts su tutte le CPU.
						\item Disabilitare gli interrupts per periodi di tempo troppo estesi può portare alla perdita di alcuni di essi. Ad esempio, la CPU può perdersi il fatto che il disco ha comunicato di aver terminato la read request.
						\item Inefficienza.	
					\end{itemize}
			\subsubsection{Load e Store}
				\begin{lstlisting}[style=CStyle]
typedef struct __lock_t { int flag; } lock_t;

void init(lock_t *mutex) {
	// 0 -> lock is available, 1 -> held
	mutex->flag = 0;
}

void lock(lock_t *mutex) {
	while (mutex->flag == 1) // TEST the flag
		; // spin-wait (do nothing)
	mutex->flag = 1; // now SET it!
}

void unlock(lock_t *mutex) {
	mutex->flag = 0;
}				\end{lstlisting}
				Viene usata una flag per indicare se un thread è in possesso del lock. Il primo thread che entrerà in sezione critica chiamerà la routine \texttt{lock()}, la quale controllerà il valore di flag e la setterà a 1 nel caso in cui essa sia uguale a 0 (a indicare che il thread è ora in possesso del lock) o farà spin-lock in caso contrario. Una volta finito la sezione critica, il thread chiama la \texttt{unlock()} e pulisce flag (rilasciando il lock). Se un altro thread chiamasse la \texttt{lock()} mentre il primo è in sezione critica, esso farà \textbf{spin-wait} nel ciclo while fino a quando non verrà chiamata la \texttt{unlock()}. Ci sono però due problemi:
				\begin{itemize}
					\item \textbf{Correctness.} È possibile che entrambi i thread settino flag a 1 ed entrino in sezione critica. Se \texttt{T1} vede il lock a 0 e prima di settarlo si ha un interrput, sia \texttt{T2} che \texttt{T1} setteranno il flag a 1 ed entreranno in sezione critica.
					\item \textbf{Performance.} Questo ciclio è chiamato ciclio di busy waiting o \textbf{spinlock}. Il thread è in uno stato di attesa che mantiene occupato il processore, vengono quindi sprecati cicli di CPU
				\end{itemize}
				
			\subsubsection{Test and Set}
				Viene implementato il supporto hardware con l'istruzione \texttt{TestAndSet}:
				\begin{lstlisting}[style=CStyle]
int TestAndSet( int *old_ptr, int new) {
	int old = *old_ptr; //prelevo vecchio valore di ptr
	olt_ptr = new;			//inserisco "new" in old_ptr
	return old;					//restituisco il vecchio valore
}				\end{lstlisting}
				Restituisce il vecchio valore puntato da \texttt{ptr} e lo aggiorna a \texttt{new}. La chiave di questo meccanismo è che questa sequenza di operazioni viene eseguita \textbf{atomicamente}. 
				\begin{lstlisting}[style=CStyle]
typedef struct __lock_t {
	int flag;
} lock_t;

void init(lock_t *lock) {
	// 0 indicates that lock is available, 1 that it is held
	lock->flag = 0;
}

void lock(lock_t *lock) {
	while (TestAndSet(&lock->flag, 1) == 1)
		; // spin-wait (do nothing)
}

void unlock(lock_t *lock) {
	lock->flag = 0;
}				\end{lstlisting}
				Con questo tipo di lock, siamo sicuri che un singolo thread potrà acquisire il lock ed entrare in sezione critica. Per funzionare correttamente su un singolo processore, ha bisogno di un \textbf{preemptive scheduler} (situazione per cui un processo viene temporaneamente interrotto e portato fuori dalla CPU), ad esempio che interromperà un thread attraverso un timer. Senza, non ha senso siccome un thread in spinning non potrà mai rinunciare al lock.
				
			\subsubsection{Algoritmo di Peterson}
				L'idea è di garantire che due thread non entrino mai in sezione critica allo stesso tempo.
				\begin{lstlisting}[style=CStyle]
int flag[2];
int turn;

void init() {
	flag[0] = flag[1] = 0;	// 1->thread wants to grab lock
	turn = 0;								// whose turn? (thread 0 or 1?)
}

void lock() {
	flag[self] = 1;		// self: thread ID of caller
	turn = 1 - self;	// make it other threads turn
	while ((flag[1-self] == 1) && (turn == 1 - self))
		; 							// spin-wait
}

void unlock() {
	flag[self] = 0;		// simply undo your intent
}				\end{lstlisting}
				Se una cella di \texttt{flag} viene settata a 1 indica che il corrispondente thread desidera entrare in sezione critica. \texttt{turn} indica il turno del thread per entrare in sezione critica.
				
			\subsubsection{Spin locks}
				\paragraph{Vantaggi} 
				\begin{itemize}
					\item Semplicità (poche righe di codice).
					\item \textbf{Correctness.} Fornisce la mutua esclusione correttamente.
				\end{itemize}								
				
				\paragraph{Svantaggi} 
					\begin{itemize}
						\item \textbf{Fairness} Non siamo in grado di garantire che ogni thread entrerà in sezione critica.
						\item \textbf{Performance} In una CPU monoprocessore lo spin lock è molto costoso. Quando abbiamo $N$ threads a contendersi il lock, nel caso peggiore verranno sprecato $N-1$ fette di tempo. In altri casi funziona ragionevolmente (\textit{se il numero di threads è più o meno uguale al numero dei processori}).
					\end{itemize}
					
			\subsubsection{Soluzioni}
				\paragraph{Dare la precedenza} ad altri thread invece che fare spinlock.
				\begin{lstlisting}[style=CStyle]
void init() {
	flag = 0;
}

void lock() {
	while (TestAndSet(&flag, 1) == 1)
		yield(); 	//rilascia la cpu
}

void unlock() {
	flag = 0;
}				\end{lstlisting}
				La primitiva \texttt{yield()} è una semplice \textbf{system call} che muove il chiamante dallo stato di running a quello di ready (\textit{deschedula il thread}). Con due thread funziona bene ma con tanti che si contendono la sezione critica no. Se un thread acquisisce la CPU e viene interrotto prima di chiamare la \texttt{unlock()}, tutti gli altri chiameranno la \texttt{lock()}, troveranno il lock occupato e chiameranno la \texttt{yield()}. Oltre al problema della \textbf{starvation }abbiamo anche problemi di \textbf{performance}.
				
				\paragraph{Sleeping instead of spinning} Lo scheduler viene lasciato troppo al caso. \texttt{Solaris} mette a disposizione due routines:
				\begin{itemize}
					\item \texttt{park()} per mettere un thread chiamante in stato di sleep.
					\item \texttt{unpark(threadID)} per svegliare un particolare thread.
				\end{itemize}
				Queste due routines possono essere usate per costruire un lock che mette il chiamante a dormire se il lock è già acquisito e lo sveglia quando è disponibile. Per evitare la starvation si usa una \textbf{coda} per controllare chi è il prossimo a prendere il lock. Inoltre, viene usata una variabile \texttt{guard} per fare spin-lock attorno a \texttt{flag} e manipolare la coda in uso dal lock. Un thread potrebbe comunque essere interrotto durante l'acquisizione o il rilascio del lock, causando gli altri thread a fare spin-wait ancora una volta. Tuttavia, il tempo speso a fare spinning è limitato (solo poche istruzioni all'interno del codice di \texttt{lock} e \texttt{unlock}.
				
				\begin{lstlisting}[style=CStyle]
typedef struct __lock_t {
	int flag;
	int guard;
	queue_t *q;
} lock_t;

void lock_init(lock_t *m) {
	m->flag = 0;
	m->guard = 0;
	queue_init(m->q);
}

void lock(lock_t *m) {
	while (TestAndSet(&m->guard, 1) == 1)
		; //acquire guard lock by spinning
	if (m->flag == 0) {
		m->flag = 1; // lock is acquired
		m->guard = 0;
	} else {
		queue_add(m->q, gettid());
		m->guard = 0;
		park();
	}
}

void unlock(lock_t *m) {
	while (TestAndSet(&m->guard, 1) == 1)
		; //acquire guard lock by spinning
	if (queue_empty(m->q))
		m->flag = 0; // let go of lock; no one wants it
	else
		unpark(queue_remove(m->q)); // hold lock (for next thread!)
	m->guard = 0;
}				\end{lstlisting}				
				
				Se \texttt{guard} fosse dopo \texttt{park()} tutti i thread successivi avrebbero trovato \texttt{guard} a 1, andando in spin-lock.
				
				\texttt{flag} non viene settata nuovamente a 0 quando un altro thread viene svegliato perchè passiamo il lock direttamente dal thread che lo rilascia al prossimo che lo acquisisce. 
				
				È Possibile che un thread sul punto di fare \texttt{park()}	venga switchato al thread in possesso del lock e che quest'ultimo lo rilasci. Ciò potrebbe portare allo sleep permanente del primo thread (\textbf{waiting race}). Si può risolvere con una terza chiamata a \texttt{setpark()} (introdotto da \texttt{Solaris}) che serve per indicare che un thread è in procito di fare \texttt{park()}. Se quindi dovesse avvenire un thread switch e un altro thread chiamasse \texttt{unpark()} prima che \texttt{park()} sia effettivamente chiamata, la successiva \texttt{park()} ritorna immediatamente invece di dormire.
				
				\begin{lstlisting}[style=CStyle]
queue_add(m->q, gettid());
setpark();
m->guard = 0;	\end{lstlisting} 
		
		\subsection{Condition Variables}
			Ci sono molti casi in cui un thread desidera controllare quando una condizione è vera prima di continuare la propria esecuzione. Per esempio un thread genitore potrebbe voler attendere il completamento del figlio prima di continuare (\texttt{join()}).
			
			\begin{lstlisting}[style=CStyle]
volatile int done = 0;

void *child(void *arg) {
	printf("child\n");
	done = 1;
	return NULL;
}

int main(int argc, char *argv[]) {
	printf("parent: begin\n");
	pthread_t c;
	Pthread_create(&c, NULL, child, NULL); // create child
	while (done == 0)
		; // spin
	printf("parent: end\n");
	return 0;
}			\end{lstlisting}
			Usare variabili condivise funziona ma è molto inefficiente, siccome il genitore spreca tempo di CPU a fare spin. Una \textbf{condition variable} è una coda esplicita in cui i threads possono mettersi quando la condizione di esecuzione non è quella desiderata. Quando lo stato cambia, il thread (uno o più) viene svegliato e può quindi riprendere la propria esecuzione.
			Una condition variable ha associate due operazioni: 
			\begin{itemize}
				\item \texttt{wait()} Mette in sleep un thread.
				\item \texttt{signal()} Viene usata quando un thread ha cambiato qualcosa nel programma e vuole quindi svegliarne uno in sleep che aspettava il verificarsi di quella condizione. 
			\end{itemize}
			La \texttt{pthread\_cond\_wait( pthread\_cond\_t *c, pthread\_mutex\_t *m)} prende anche un mutex come parametro. Si assume che questo mutex sia \textbf{locked} quando la \texttt{wait()} viene invocata. La responsabilità della wait è di liberare il lock e mettere il thread chiamante in stato di sleep (atomicamente). Quando un thread viene svegliato, deve acquisire nuovamente il lock prima di ritornare dalla \texttt{wait()} (per prevenire la race condition). Una soluzione al problema del \texttt{join()}:
			\begin{lstlisting}[style=CStyle]
int done = 0;
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t c = PTHREAD_COND_INITIALIZER;

void thr_exit() {
	Pthread_mutex_lock(&m);
	done = 1;
	Pthread_cond_signal(&c);
	Pthread_mutex_unlock(&m);
}

void *child(void *arg) {
	printf("child\n");
	thr_exit();
	return NULL;
}

void thr_join() {
	Pthread_mutex_lock(&m);
	while (done == 0)
		Pthread_cond_wait(&c, &m);
	Pthread_mutex_unlock(&m);
}

int main(int argc, char *argv[]) {
	printf("parent: begin\n");
	pthread_t p;
	Pthread_create(&p, NULL, child, NULL);
	thr_join();
	printf("parent: end\n");
	return 0;
}			\end{lstlisting}
			\subsubsection{Approcci sbagliati}
				\paragraph{Senza la variabile done} se il figlio viene eseguito immediatamente e chiama la \texttt{thr\_exit()}, essa chiamerà la \texttt{signal()}, ma non ci sono thread in sleep sulla condizione. Quando il genitore verrà eseguito chiamerà la \texttt{wait()} e rimarrà bloccato, nessun thread lo sveglierà mai. 
			
				\paragraph{Senza il lock} se il genitore chiama \texttt{thr\_join()} e controlla il valore di done, vedrà che è a zero e si metterà in sleep. Prima di chiamare la wait viene interrotto e viene eseguito il figlio. Quest'ultimo cambia \texttt{done} a 1 e chiama \texttt{signal()} ma non c'è nessun thread in attesa del verificarsi della condizione. Quando il genitore viene nuovamente eseguito, andrà a dormire per sempre.
			
				Vanno usati sempre i \textbf{cicli while} per i controlli.
			
			\subsubsection{Produttore e consumatore}
				I thread produttori generano i dati e li inseriscono in un buffer, i consumatori prendono questi dati dal buffer e li consumano in un certo modo. Il buffer è una risorsa condivisa ed è necessario sincronizzare l'acesso ad essa per evitare la race condition.
				\begin{lstlisting}[style=CStyle]
int buffer;
int count = 0; // initially, empty

void put(int value) {
	assert(count == 0);
	count = 1;
	buffer = value;
}

int get() {
	assert(count == 1);
	count = 0;
	return buffer;
}				\end{lstlisting}
				\begin{itemize}
				\item \texttt{put()}, assumendo che il buffer sia vuoto, inserisce semplicemente un valore in esso e lo marca come "pieno" settando la variabile \texttt{count}. 
				\item \texttt{get()} fa l'opposto, settando il buffer a vuoto (\texttt{count = 0}) e restituisce il valore prelevato.
				\end{itemize}
				\begin{lstlisting}[style=CStyle]
cond_t cond;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);
		if (count == 1)			//questo verra' cambiato con un while
			Pthread_cond_wait(&cond, &mutex);
		put(i);
		Pthread_cond_signal(&cond);
		Pthread_mutex_unlock(&mutex);
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);
		if (count == 0)			//questo verra' cambiato con un while
			Pthread_cond_wait(&cond, &mutex);
		int tmp = get();
		Pthread_cond_signal(&cond);
		Pthread_mutex_unlock(&mutex);
		printf("%d\n", tmp);
	}
}				\end{lstlisting}
				Con un singolo produttore e un singolo consumatore, il codice sopra funziona, ma se abbiamo ad esempio due consumatori, la soluzione due problemi critici:
				\begin{itemize}
					\item Supponiamo che ci siano due consumatori e un produttore:
					\begin{itemize}
						\item $C_1$ acquisisce il lock e controlla che ogni buffer sia pronto per la consumazione ma non ce ne sono, chiama la \texttt{wait}. 
						\item $P_1$ viene eseguito, acquisisce il lock e controlla che tutti buffer siano pieni, ma non lo sono. Va avanti riempendo il buffer. Invoca la \texttt{signal()} per informare che il buffer è stato riempito.
						\item $C_1$ si muove nella coda di ready dallo stato di sleeping sulla condition variable (\textit{non viene ancora eseguito}). 
						\item $P_1$ continua fino a quando non realizza che il buffer è pieno, e poi va in sleep.
						\item $C_2$ viene eseguito e consuma il valore nel buffer (salta la \texttt{wait} perchè il buffer è pieno).
						\item $C_1$ viene ora eseguito, prima di ritornare dalla \texttt{wait()}, acquisisce nuovamente il lock, chiama la \texttt{get()} ma \textbf{non ci sono buffer da consumare}.
						
						Il problema è questo: dopo che il produttore sveglia $C_1$, ma prima che esso venga eseguito, lo stato del buffer è cambiato (per colpa di $C_2$). Segnalare un thread lo sveglia solamente dicendogli che lo stato è cambiato (in questo caso che un valore è stato messo nel buffer), ma non ci sono garanzie che quando il thread svegliato venga eseguito lo stato sia lo stesso (\textbf{Mesa semantics}). 
						
						Soluzione: cambiare l'\textbf{if} in \textbf{while} in modo che se $C_1$ viene svegliato ricontrolla immediatamente lo stato della variabile condivisa. Se il buffer è vuoto, tornerà semplicemente a dormire.
					\end{itemize}
					\item C'è una sola condition variable.
					\begin{itemize}
						\item Vengono eseguiti prima $C_1$ e $C_2$ e vanno in sleep.
						\item Il produttore mette un valore nel buffer e sveglia uno dei consumatori, diciamo $C_1$.
						\item Il produttore torna indietro e prova a inserire più dati nel buffer, siccome è pieno il produttore chiamerà \texttt{wait()} e andrà a dormire.
						\item $C_1$ è pronto per essere eseguito e \textbf{due threads stanno dormendo sulla condizione} ($C_2$ e $P_1$).
						\item $C_1$ Si sveglia ritornando dalla \texttt{wait()}, controlla nuovamente la condizione e trova che il buffer è pieno. Consuma il valore e segnala la condizione, svegliando un thread in sleeping. \textbf{Quale dei due sveglia?} Se svegliasse il consumatore, troverà il buffer vuoto e si metterà in sleep. Il produttore viene lasciato a dormire. Tutti e tre i threads sono in stato di sleeping. Un \textbf{consumatore non dovrebbe poter svegliare altri consumatori}, ma solo produttori (e viceversa).
					\end{itemize}
					La soluzione è usare due condition variables per segnalare correttamente quale tipo di thread andrebbe svegliato.
				\end{itemize}
				\begin{lstlisting}[style=CStyle]
int buffer[MAX];
int fill = 0;
int use = 0;
int count = 0;

void put(int value) {
	buffer[fill] = value;
	fill = (fill + 1) % MAX;
	count++;
}

int get() {
	int tmp = buffer[use];
	use = (use + 1) % MAX;
	count--;
	return tmp;
}

cond_t empty, fill;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);	
		while (count == MAX)
			Pthread_cond_wait(&empty, &mutex); 
		put(i);
		Pthread_cond_signal(&fill);
		Pthread_mutex_unlock(&mutex);
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);
		while (count == 0)
			Pthread_cond_wait(&fill, &mutex);
		int tmp = get();
		Pthread_cond_signal(&empty);
		Pthread_mutex_unlock(&mutex);
		printf("%d\n", tmp);
	}
}				\end{lstlisting}
				I thread produttori aspettano sulla condizione \texttt{empty} e segnalano \texttt{fill}, per i consumatori l'inverso. Inoltre per abilitare più concorrenza ed efficienza si aggiungono più slot al buffer, in modo tale che più valori possano essere prodotti o consumati prima di andare in sleep. Un produttore dorme solo se tutti i buffer sono pieni, un consumatore dorme solo se tutti i buffer sono vuoti.
		\subsection{Semafori}
			Un semaforo è un oggetto con un valore di tipo integer utilizzabili sia come locks che come condition variables.
			\\Il valore iniziale di un semaforo ne determina il comportamento.
			\begin{lstlisting}[style=CStyle]
#include <semaphore.h>
sem_t s;
sem_init(&s, 0, 1);			\end{lstlisting}
			Il secondo valore di \texttt{sem\_init()} viene settato a 0 e indica che il semaforo è condiviso tra thread dello stesso processo. Il terzo argomento è il valore con cui lo si inizializza. Per interagire con esso vengono introdotte due routines: 
			\begin{itemize}
				\item \texttt{sem\_wait(sem\_t *s)} decrementa il valore del semaforo \texttt{s} di uno e aspetta se il valore del semaforo è negativo.
				\item \texttt{sem\_post(sem\_t *s)} incrementa il valore del semaforo \texttt{s} di uno, se ci sono uno o più threads in attesa ne sveglia uno.
			\end{itemize}
			
			Il valore del semaforo, quando negativo, è uguale al numero di thread in attesa.
			\subsubsection{Semafori binari: locks}
				Per implementare i lock, il codice sarà: 
				\begin{lstlisting}[style=CStyle]
sem_t m;
sem_init(&m, 0, 1); //inizializza il semaforo a 1
sem_wait(&m);
//sezione critica
sem_post(&m); 	\end{lstlisting}
				Il valore di partenza del semaforo \texttt{m} a 1  è critico per la realizzazione del lock. I semafori \textbf{binari} possono trovarsi solamente in due  stati: acquisito o disponibile. 
			
			\subsubsection{Semafori per ordinare}
				I semafori possono essere usati anche come condition variables, esempio: 
				\begin{lstlisting}[style=CStyle]
sem_t s;

void *child(void *arg) {
	printf("child\n");
	sem_post(&s); // signal here: child is done
	return NULL;
}

int main(int argc, char *argv[]) {
	sem_init(&s, 0, 0); //Inizializzo a 0 per forza
	printf("parent: begin\n");
	pthread_t c;
	Pthread_create(c, NULL, child, NULL);
	sem_wait(&s); // wait here for child
	printf("parent: end\n");
	return 0;
}				\end{lstlisting}
				In questo modo ci aspettiamo di avere come risultato: \texttt{parent: begin, child, parent: end}
			
			\subsubsection{Semafori come produttore e consumatore}
				Si usano due semafori, \texttt{empty} e \texttt{full}, che indicano quando una entry del buffer è stata svuotata o riempita rispettivamente.
				\begin{lstlisting}[style=CStyle]
int buffer[MAX];
int fill = 0;
int use = 0;

void put(int value) {
	buffer[fill] = value;
	fill = (fill + 1) % MAX; 
}

int get() {
	int tmp = buffer[use];
	use = (use + 1) % MAX;
	return tmp;
}				\end{lstlisting}
				Produttori e consumatori: 
				\begin{lstlisting}[style=CStyle]
sem_t empty;
sem_t full;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		sem_wait(&empty);
		put(i);
		sem_post(&full);
	}
}

void *consumer(void *arg) {
	int i, tmp = 0;
	while (tmp != -1) {
		sem_wait(&full);
		tmp = get();
		sem_post(&empty);
		printf("%d\n", tmp);
	}
}

int main(int argc, char *argv[]) {
// ...
sem_init(&empty, 0, MAX); //MAX buffers are empty to begin with
sem_init(&full, 0, 0); // ... and 0 are full
// ...
}				\end{lstlisting}
				Il produttore aspetta che il buffer diventi vuoto per poterlo riempire di dati e il consumatore attende che il buffer sia pieno prima di consumare i dati. Con un singolo consumatore e un produttore funziona bene, con \texttt{MAX = 10} abbiamo un problema di \textbf{race condition}:
				\begin{itemize}
					\item Abbiamo due produttori in procinto di chiamare la \texttt{put()}
					\item $P_1$ viene eseguito prima e inizia a riempire il buffer. Prima che esso incrementi \texttt{fill} a 1, viene interrotto. 
					\item Il produttore $P_2$ inizia ad essere eseguito e anche lui, inserisce i suoi dati nello stesso punto del buffer sovrascrivendo quelli vecchi. 
				\end{itemize}
				Manca la \textbf{mutua esclusione}, riempire il buffer e incrementare il contatore è una porzione di codice critica. Basta aggiungere i semafori binari come locks. Inizialmente può sembrare una buona idea metterli intorno a \texttt{wait} e \texttt{post}, ma questo potrebbe portare a un \textbf{deadlock}. 
				\begin{itemize}
					\item Il consumatore viene eseguito e acquisisce mutex. 
					\item Chiama la \texttt{sem\_wait(\&full)}. Possiede ancora il lock.
					\item Viene eseguito un produttore che, se fosse possibile, riempirebbe il buffer di dati e sveglierebbe il consumatore. Chiama \texttt{sem\_wait(\&mutex)}. Il lock è già in possesso del consumatore e il produttore è bloccato ad aspettare. Il consumatore ha il lock ed è in waiting, produttore non ha il lock, ed è in waiting.
				\end{itemize}
				Si sposta quindi il mutex intorno solo alla \texttt{get()} e alla \texttt{put()} e si ottiene il seguente codice: 
				\begin{lstlisting}[style=CStyle]
sem_t empty;
sem_t full;
sem_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		sem_wait(&empty);
		sem_wait(&mutex);	//(MOVED MUTEX HERE...)
		put(i);
		sem_post(&mutex);	//(... AND HERE)
		sem_post(&full);
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		sem_wait(&full);
		sem_wait(&mutex);	//(MOVED MUTEX HERE...)
		int tmp = get();
		sem_post(&mutex);	//(... AND HERE)
		sem_post(&empty);
		printf("%d\n", tmp);
	}
}

int main(int argc, char *argv[]){
	// ...
	sem_init(&empty, 0, MAX);//MAX buffers are empty to begin with
	sem_init(&full, 0, 0);   // ... and 0 are full
	sem_init(&mutex, 0, 1);  // mutex=1 because it is a lock
	// ...
}				\end{lstlisting}
			\subsubsection{Implementazione dei semafori}
				\begin{lstlisting}[style=CStyle]
typedef struct __Zem_t {
	int value;
	pthread_cond_t cond;
	pthread_mutex_t lock;
} Zem_t;

// only one thread can call this
void Zem_init(Zem_t *s, int value) {
	s->value = value;
	Cond_init(&s->cond);
	Mutex_init(&s->lock);
}

void Zem_wait(Zem_t *s) {
	Mutex_lock(&s->lock);
	while (s->value <= 0)
		Cond_wait(&s->cond, &s->lock);
	s->value--;
	Mutex_unlock(&s->lock);
}

void Zem_post(Zem_t *s) {
	Mutex_lock(&s->lock);
	s->value++;
	Cond_signal(&s->cond);
	Mutex_unlock(&s->lock);
}				\end{lstlisting}

		\subsection{Problemi relativi alla concorrenza}
			\subsubsection{Non-deadlock bugs}
				\paragraph{Atomicity-violation bug} consiste nel non mettere dei \textbf{locks} attorno ad una variabile condivisa.
				\paragraph{Order-violation bug} consiste nel non assegnare un ordine a due thread che accedono alla stessa variabile. Ad esempio, un thread potrebbe dare per scontato che una variabile sia già inizializzata ed utilizzarla, ma se è ancora a \texttt{NULL} questo causerà un crash. Per risolvere questo bug, basta usare le \textbf{condition variables}.
				
			\subsubsection{Deadlock bugs}
				I deadlock avvengono quando un thread $T_1$ è in possesso del lock $L_1$ e in attesa di un altro $L_2$; il thread $T_2$ che possiede il lock $L_2$ è in attesa che $L_1$ venga rilasciato.
				\begin{lstlisting}[style=CStyle]
Thread 1:									Thread 2:
pthread_mutex_lock(L1);		pthread_mutex_lock(L2);
pthread_mutex_lock(L2);		pthread_mutex_lock(L1);\end{lstlisting}
				Le ragioni per cui i deadlock avvengono possono essere: 
				\begin{itemize}
					\item Troppo codice
					\item Dipendenze complesse tra i componenti.
					\item L'incapsulamento del codice.
				\end{itemize}
				Affinchè avvenga un deadlock devono essere valide quattro condizioni: 
				\begin{itemize}
					\item \textbf{Mutua esclusione} I threads richiedono il controllo escluso delle risorse che acquisiscono.
					\item \textbf{Hold-and-wait} I thread tengono le risorse allocate da essi (ad esempio i locks che hanno già acquisito) finchè aspettano risorse addizionali (ad esempio i lock che vogliono acquisire).
					\item \textbf{No preemption} Le risorse (ad esempio i locks) non possono essere rimosse forzatamente dai threads che le stanno tenendo.
					\item \textbf{Circular wait} Esistono catene circolari di threads.
				\end{itemize}
				\textbf{Se una qualunque di queste condizioni non è soddisfatta, un deadlock non può avvenire.}
			\subsubsection{Prevenzione dei deadlocks}
				\begin{itemize}
					\item \textbf{Circular wait} La miglior tecnica di prevenzione è fornire un acquisizione del lock ordinata. Per esempio, possiamo prevenire il deadlock acquisendo sempre $L_1$ prima di $L_2$. Questo ordine consente di evitare wait cicliche e quindi deadlock.
					\item \textbf{Hold-and-wait} Per evitare il deadlock dovuto a questa condizione basta acquisire tutti i locks in una volta atomicamente, in modo da evitare che non ci siano thread switch prematuri nel mezzo dell'acquisizione del lock. La soluzione però è problematica: richiede di sapere esattamente quali locks devono essere posseduti e di acquisirli tutti in una volta. Tutti i locks devono essere acquisiti in una volta anche se non è necessario possederli tutti.
					\item \textbf{No preemption} Per non dare tutti i locks come acquisiti fino a quando la \texttt{unlock()} non viene invocata, si può usare una routine come \texttt{pthread\_mutex\_trylock()} che prende il lock (se disponibile) e ritorna \textbf{success} o un codice di errore se il lock è già posseduto. Questo per evitare l'acquisizione multipla di locks, perchè potremmo aspettarne uno mentre siamo in possesso di un altro. Sorge un nuovo problema, la \textbf{livelock}. 
					\begin{lstlisting}[style=CStyle]
top:
pthread_mutex_lock(L1);
if(pthread_mutex_trylock(L2) != 0) {
	pthread_mutex_unlock(L1);
	goto top;
}					\end{lstlisting}					
					È possibile che due threads tentino ripetutamente questa sequenza e falliscano nell'acquisire il lock. Si può risolvere con un delay random prima di fare il loop back.
					\item \textbf{Mutua esclusione} Si possono utilizzare itruzioni hardware per evitare di usare i locks, in questo modo non sarebbe possibile che si verifichino deadlocks (livelock può comunque accadere).
				\end{itemize}

				
			
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage	\section{Persistence}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{JOS}


\end{document}
